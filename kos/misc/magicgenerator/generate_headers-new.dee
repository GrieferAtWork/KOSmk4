/* Copyright (c) 2019-2020 Griefer@Work                                       *
 *                                                                            *
 * This software is provided 'as-is', without any express or implied          *
 * warranty. In no event will the authors be held liable for any damages      *
 * arising from the use of this software.                                     *
 *                                                                            *
 * Permission is granted to anyone to use this software for any purpose,      *
 * including commercial applications, and to alter it and redistribute it     *
 * freely, subject to the following restrictions:                             *
 *                                                                            *
 * 1. The origin of this software must not be misrepresented; you must not    *
 *    claim that you wrote the original software. If you use this software    *
 *    in a product, an acknowledgement (see the following) in the product     *
 *    documentation is required:                                              *
 *    Portions Copyright (c) 2019-2020 Griefer@Work                           *
 * 2. Altered source versions must be plainly marked as such, and must not be *
 *    misrepresented as being the original software.                          *
 * 3. This notice may not be removed or altered from any source distribution. *
 */

import * from deemon;
import * from errors;
import * from ..libgen.c.cheaders;
import * from ..libgen.c.escape;
import * from ..libgen.c.parser;
import * from ..libgen.c.writer;
import * from ..libgen.c.loader;
import * from ..libgen.c.globals;
import Function from ..libgen.c.cheaders;
import hash from hashlib;
import fs;

fs.chdir(fs.headof(__FILE__) + "/../../");

final global HASH_FUNCTION = "CRC-32";

@@The max # of tasks that may be run in parallel
final global MAX_RUNNING_TASKS = (cpu_count from posix)();

@@List of all tasks that are currently being run
global runningTasks: {Thread...} = [];

@@Start a new task that'll execute @cb with @args
function startTask(cb: Callable, args: {Object...} = ()) {
	for (;;) {
		local n = #runningTasks;
		if (n < MAX_RUNNING_TASKS)
			break;
		for (local i = 0; i < n;) {
			if (runningTasks[i].tryjoin()[0]) {
				runningTasks.erase(i);
				--n;
				continue;
			}
			++i;
		}
		if (n < MAX_RUNNING_TASKS)
			break;
		Thread.sleep((milliseconds from time)(100));
	}
	local t = Thread(cb, args);
	t.start();
	runningTasks.append(t);
}

@@Wait for all running tasks to finish
function waitTasks() {
	while (runningTasks)
		runningTasks.popback().join();
}

@@Update the contents of @filename, using a file-printer callback @cb
function updateHashedFile(filename: string, cb: Callable with File) {
	local fp: File = File.Writer();
	print "Printing:", repr filename;
	local result = cb(fp);
	local newText: Bytes = fp.string.encode("utf-8");
	local newTextHash: int = hash(HASH_FUNCTION, newText);
again:
	try {
		fp = File.open(filename, "rb+");
	} catch (FileNotFound) {
		try {
			fp = File.open(filename, "wronly,creat,excl");
		} catch (FileExists) {
			goto again;
		}
		/* Create a previously non-existant file */
		print "Creating:", repr filename;
		try {
			with (fp) {
				fp << "/* HASH " << HASH_FUNCTION << ":" << newTextHash.hex() << " */\n";
				fp.write(newText);
			}
		} catch (...) {
			try {
				fs.unlink(filename);
			} catch (...) {
			}
			throw;
		}
		goto done;
	}
	/* File already exists.
	 * -> Read in the existing file, and check if its contents match its hash.
	 *    If they don't, then throw an Error.
	 * -> If the contents match the new contents for the file, then don't do anything.
	 * -> If the contents did change, then re-write the new contents to the file */
	local oldText: Bytes;
	local oldTextHashFunction: string;
	local oldTextHash: int, oldTextRealHash: int;
	try {
		local oldTextWhole: Bytes = fp.readall();
		oldTextHashFunction, oldTextHash = oldTextWhole
			.scanf(" /* HASH %[^:]:%[0-9xXa-fA-F] */")...;
		oldText = oldTextWhole[oldTextWhole.index("\n") + 1:];
		oldTextHashFunction = oldTextHashFunction.strip().decode("utf-8");
		oldTextHash         = int(oldTextHash.strip());
		oldTextRealHash     = hash(oldTextHashFunction, oldText);
	} catch (...) {
		throw Error("File {!r} is lacking, or has a broken hash header"
			.format({ filename }));
	}
	if (oldTextHash != oldTextRealHash) {
		throw Error("File {!r} has been modified (hash miss-match: expected {!r}, but got {!r})"
			.format({ oldTextRealHash.hex(), oldTextHash.hex() }));
	}
	if (oldTextHash == newTextHash) {
		if (oldText == newText)
			goto done;
	}
	try {
		print "Updating:", repr filename;
		fp.rewind();
		with (fp) {
			fp << "/* HASH " << HASH_FUNCTION << ":" << newTextHash.hex() << " */\n";
			fp.write(newText);
			fp.trunc();
		}
	} catch (...) {
		try {
			fs.unlink(filename);
		} catch (...) {
		}
		throw;
	}
done:
	return result;
}



@@Set of known user libc exports (populated by %[declare_user_export(...)])
global final knownUserExports: {string...} = HashSet();

@@Set of known kernel exports (populated by %[declare_kernel_export(...)])
global final knownKernelExports: {string...} = HashSet();

@@Set of known libc section names
global final knownLibcSections: {string...} = HashSet();

@@Parse custom directives that are so obscure that
@@they shouldn't be part of the standard loader
@@@return: * : Indicative of the directive having been recognized.
function customDirectivesParser(context: LoaderContext): bool {
	local self = context.self;
	local tok = self.tok;
	switch (tok) {

	case "define_ssp":
	case "define_ssp_builtin":
	case "define_ssp_undef":
	case "define_ssp_builtin_undef":
	case "define_ssp_crt":
	case "define_ssp_builtin_crt":
	case "define_ssp_undef_crt":
	case "define_ssp_builtin_undef_crt": {
		local define_builtin = "builtin" in tok;
		local undef_existing = "undef" in tok;
		local check_crt      = "crt" in tok;
		self.next();
		self.skip("(");
		local a = str parseCStringOrFunctionLikeExpression(self);
		self.skip("=");
		local b = str parseCStringOrFunctionLikeExpression(self);
		self.skip(")");
		local aName = a.partition("(")[0].strip();
		local baseFunctionName = b.lstrip("_").partition("_chk")[0];
		File.Writer fp;
		if (define_builtin) {
			fp << "#if (defined(__LIBC_BIND_CRTBUILTINS) && defined(__CRT_HAVE_" << baseFunctionName << ") && \\\n";
			fp << "     defined(__CRT_HAVE___" << baseFunctionName << "_chk) && __has_builtin(__builtin___" << baseFunctionName << "_chk))\n";
			if (undef_existing)
				fp << "#undef " << aName << "\n";
			local bos_start = b.index("__ssp_bos");
			local bos = b[bos_start:b.indexmatch("(", ")", b.index("(", bos_start) + 1) + 1].strip();
			fp << "#define " << a << (" " * ((#b + #bos + 31) - #a)) << " \\\n";
			fp << "\t(" << bos << " != (__SIZE_TYPE__)-1 ? __builtin_" << b << " \\\n";
			fp << "\t" << (" " * (#bos + 23)) << ": " << b << ")\n";
			if (check_crt)
				fp << "#elif defined(__CRT_HAVE___" << baseFunctionName << "_chk)\n";
			else {
				fp << "#else /* ... */\n";
			}
		} else {
			if (check_crt)
				fp << "#ifdef __CRT_HAVE___" << baseFunctionName << "_chk\n";
		}
		if (undef_existing)
			fp << "#undef " << aName << "\n";
		fp << "#define " << a << " " << b << "\n";
		if (define_builtin) {
			if (check_crt) {
				fp << "#endif /* ... */\n";
			} else {
				fp << "#endif /* !... */\n";
			}
		} else if (check_crt) {
			fp << "#endif /* __CRT_HAVE___" << baseFunctionName << "_chk */\n";
		}
		context.insertText_c(fp.string);
	}	break;


	case "declare_user_export":
	case "declare_kernel_export":
	case "declare_known_section": {
		local s = tok == "declare_user_export"
			? knownUserExports
			: tok == "declare_kernel_export"
			? knownKernelExports
			: knownLibcSections;
		self.next();
		tok = self.skip("(");
		while (tok !in ["", ")"]) {
			local name = parseCStringOrFunctionLikeExpression(self);
			s.insert(name);
			if (self.tok != ",")
				break;
			tok = self.next();
		}
		self.skip(")");
	}	break;

	default:
		return false;
	}
	return true;
}

@@Compile a given system header source file @filename
function compileSystemHeaderSourceFile(filename: string, headerName: string) {
	print "Compiling:", filename, "(begin)";
	local parser = CParser(File.open(filename), filename: filename);
	loadSystemHeaderDefinitions(
		self:                   parser,
		headerName:             headerName,
		customDirectivesParser: customDirectivesParser);
	print "Compiling:", filename, "(end)";
}


#define SINGLE_HEADER_TEST "aliases"

try {
	local runningTasks = [];
	/* Load all the definitions files */
	local LIBC_PATH = "src/libc/magic";
	for (local filename: fs.query(LIBC_PATH + "/*.c")) {
#ifdef SINGLE_HEADER_TEST
		if (filename != SINGLE_HEADER_TEST ".c")
			continue;
#endif /* SINGLE_HEADER_TEST */
		local fullPath = fs.abspath(LIBC_PATH + "/" + filename);
		/* XXX: There are only a couple of ways by which different definition
		 *      files actually interact with each other:
		 *  - %[define_replacement(...)]
		 *  - %[define_wchar_replacement(...)]
		 *  - %[define_XXX_replacement(...)]
		 *  - %[insert:extern(...)]
		 *  - foo(*) = bar;
		 * We could create some sort of database that contains information about
		 * which source files define some feature/function, which might allow us
		 * to not have to re-compile everything anything something changes!
		 */
		startTask(compileSystemHeaderSourceFile,
			(fullPath, fs.fileof(filename)));
	}
	waitTasks();

	/* Generate the actual system headers (i.e. <string.h>) */
	for (local name /*: string*/, header /*: SystemHeader*/: allSystemHeaders) {
#ifdef SINGLE_HEADER_TEST
		if (name != SINGLE_HEADER_TEST)
			continue;
#endif /* SINGLE_HEADER_TEST */
		startTask(updateHashedFile,
			("include/{}.h".format({ name.replace(".", "/") }),
			[](fp: File) {
				fp << COPYRIGHT << "\n";
				local cWriter = CWriter(fp);
				header.cprintHeader(cWriter, ESCAPE_MODE_PART);
				cWriter.flush();
			})
		);
	}
	waitTasks();

} catch (e...) {
	print repr e;
	print repr Traceback.current;
	Error.AppExit.exit(1);
}
print "DONE";
Error.AppExit.exit(0);



